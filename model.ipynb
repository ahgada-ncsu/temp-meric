{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_grep_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matcher</th>\n",
       "      <th>regex_length</th>\n",
       "      <th>regex_complexity</th>\n",
       "      <th>input_file_size (bytes)</th>\n",
       "      <th>execution_time (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-E</td>\n",
       "      <td>12</td>\n",
       "      <td>7.2</td>\n",
       "      <td>873045</td>\n",
       "      <td>23.861249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-E</td>\n",
       "      <td>12</td>\n",
       "      <td>7.2</td>\n",
       "      <td>271635</td>\n",
       "      <td>16.129971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-E</td>\n",
       "      <td>12</td>\n",
       "      <td>7.2</td>\n",
       "      <td>566610</td>\n",
       "      <td>15.757958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-E</td>\n",
       "      <td>12</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1786200</td>\n",
       "      <td>39.776882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-E</td>\n",
       "      <td>12</td>\n",
       "      <td>7.2</td>\n",
       "      <td>62860</td>\n",
       "      <td>8.767207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17575</th>\n",
       "      <td>-x</td>\n",
       "      <td>63</td>\n",
       "      <td>46.3</td>\n",
       "      <td>2836320</td>\n",
       "      <td>6.530364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17576</th>\n",
       "      <td>-x</td>\n",
       "      <td>63</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1746090</td>\n",
       "      <td>5.733649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17577</th>\n",
       "      <td>-x</td>\n",
       "      <td>63</td>\n",
       "      <td>46.3</td>\n",
       "      <td>403054</td>\n",
       "      <td>3.797213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17578</th>\n",
       "      <td>-x</td>\n",
       "      <td>63</td>\n",
       "      <td>46.3</td>\n",
       "      <td>166280</td>\n",
       "      <td>3.627380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17579</th>\n",
       "      <td>-x</td>\n",
       "      <td>63</td>\n",
       "      <td>46.3</td>\n",
       "      <td>24183240</td>\n",
       "      <td>23.396095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17580 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      matcher  regex_length  regex_complexity  input_file_size (bytes)  \\\n",
       "0          -E            12               7.2                   873045   \n",
       "1          -E            12               7.2                   271635   \n",
       "2          -E            12               7.2                   566610   \n",
       "3          -E            12               7.2                  1786200   \n",
       "4          -E            12               7.2                    62860   \n",
       "...       ...           ...               ...                      ...   \n",
       "17575      -x            63              46.3                  2836320   \n",
       "17576      -x            63              46.3                  1746090   \n",
       "17577      -x            63              46.3                   403054   \n",
       "17578      -x            63              46.3                   166280   \n",
       "17579      -x            63              46.3                 24183240   \n",
       "\n",
       "       execution_time (ms)  \n",
       "0                23.861249  \n",
       "1                16.129971  \n",
       "2                15.757958  \n",
       "3                39.776882  \n",
       "4                 8.767207  \n",
       "...                    ...  \n",
       "17575             6.530364  \n",
       "17576             5.733649  \n",
       "17577             3.797213  \n",
       "17578             3.627380  \n",
       "17579            23.396095  \n",
       "\n",
       "[17580 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2[\"matcher\"] = df[\"matcher\"]\n",
    "df2[\"regex_length\"] = df[\"regex_length\"]\n",
    "df2[\"regex_complexity\"] = df[\"regex_complexity\"]\n",
    "df2[\"input_file_size (bytes)\"] = df[\"input_file_size (bytes)\"]\n",
    "df2[\"execution_time (ms)\"] = df[\"execution_time (ms)\"]\n",
    "df = df2.copy()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Split Information:\n",
      "Total samples: 17580\n",
      "Training samples: 14064 (80.0%)\n",
      "Testing samples: 3516 (20.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amaygada/anaconda3/envs/DL/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Summary:\n",
      "       Model  Acc1\\n(0.8 < y_pred/y_true < 1.2)  Acc2\\n(0.9 < y_pred/y_true < 1.1)  MAPE\n",
      "DecisionTree                             0.4568                             0.2750 0.459\n",
      "RandomForest                             0.4983                             0.2787 0.508\n",
      "     XGBoost                             0.3859                             0.2071 0.524\n",
      "\n",
      "Best Parameters:\n",
      "\n",
      "DecisionTree:\n",
      "max_depth: 10\n",
      "min_samples_leaf: 1\n",
      "min_samples_split: 2\n",
      "\n",
      "RandomForest:\n",
      "max_depth: 10\n",
      "min_samples_leaf: 1\n",
      "min_samples_split: 5\n",
      "n_estimators: 100\n",
      "\n",
      "XGBoost:\n",
      "learning_rate: 0.1\n",
      "max_depth: 7\n",
      "min_child_weight: 3\n",
      "n_estimators: 100\n",
      "\n",
      "Feature Importance (Random Forest):\n",
      "                   Feature  Importance\n",
      "2  input_file_size (bytes)    0.225527\n",
      "1         regex_complexity    0.213474\n",
      "5               matcher_-P    0.154620\n",
      "4               matcher_-G    0.106464\n",
      "0             regex_length    0.105110\n",
      "3               matcher_-F    0.102154\n",
      "6               matcher_-x    0.092651\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load and preprocess data\n",
    "def preprocess_data(df):\n",
    "    # Create copy to avoid modifications to original data\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Define feature columns with exact names\n",
    "    categorical_features = ['matcher']\n",
    "    numeric_features = ['regex_length', 'regex_complexity', 'input_file_size (bytes)']\n",
    "    target = 'execution_time (ms)'\n",
    "    \n",
    "    # Create preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', MinMaxScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(drop='first', sparse=False), categorical_features)\n",
    "        ])\n",
    "    \n",
    "    # Create feature matrix X and target variable y\n",
    "    X = df[categorical_features + numeric_features]\n",
    "    y = df[target]\n",
    "    \n",
    "    # Fit and transform the data\n",
    "    X_transformed = preprocessor.fit_transform(X)\n",
    "    \n",
    "    # Get feature names after transformation\n",
    "    onehot_features = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "    feature_names = np.concatenate([numeric_features, onehot_features])\n",
    "    \n",
    "    # Convert to DataFrame to maintain feature names\n",
    "    X_transformed_df = pd.DataFrame(X_transformed, columns=feature_names)\n",
    "    \n",
    "    return X_transformed_df, y, preprocessor\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "\n",
    "# Initialize models with parameter grids\n",
    "models = {\n",
    "    'DecisionTree': {\n",
    "        'model': DecisionTreeRegressor(random_state=42),\n",
    "        'params': {\n",
    "            'max_depth': [3, 5, 7, 10],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestRegressor(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [5, 10],\n",
    "            'min_samples_split': [2, 5],\n",
    "            'min_samples_leaf': [1, 2]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBRegressor(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'min_child_weight': [1, 3]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Preprocess data\n",
    "X_transformed_df, y, preprocessor = preprocess_data(df)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_transformed_df, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nDataset Split Information:\")\n",
    "print(f\"Total samples: {len(X_transformed_df)}\")\n",
    "print(f\"Training samples: {len(X_train)} ({len(X_train)/len(X_transformed_df)*100:.1f}%)\")\n",
    "print(f\"Testing samples: {len(X_test)} ({len(X_test)/len(X_transformed_df)*100:.1f}%)\")\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model_info in models.items():\n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        model_info['model'],\n",
    "        model_info['params'],\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = evaluate_model(y_test, y_pred)\n",
    "    results[name] = {\n",
    "        'metrics': metrics,\n",
    "        'best_params': grid_search.best_params_\n",
    "    }\n",
    "\n",
    "# Create results DataFrame in the requested format\n",
    "acc1_values = []\n",
    "acc2_values = []\n",
    "mape_values = []\n",
    "model_names = []\n",
    "\n",
    "\n",
    "for model_name, model_results in results.items():\n",
    "    y_pred = models[model_name]['model'].fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    # Calculate ratio of predicted to true values\n",
    "    ratio = y_pred / y_test\n",
    "    \n",
    "    # Calculate accuracy metrics\n",
    "    acc1 = np.mean((ratio >= 0.8) & (ratio <= 1.2))\n",
    "    acc2 = np.mean((ratio >= 0.9) & (ratio <= 1.1))\n",
    "    mape = model_results['metrics']['MAPE']\n",
    "    \n",
    "    # Append values\n",
    "    model_names.append(model_name)\n",
    "    acc1_values.append(round(acc1, 4))\n",
    "    acc2_values.append(round(acc2, 4))\n",
    "    mape_values.append(round(mape, 3))\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Acc1\\n(0.8 < y_pred/y_true < 1.2)': acc1_values,\n",
    "    'Acc2\\n(0.9 < y_pred/y_true < 1.1)': acc2_values,\n",
    "    'MAPE': mape_values\n",
    "})\n",
    "\n",
    "# Sort results by MAPE (ascending) to show best performing models first\n",
    "results_df = results_df.sort_values('MAPE', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Display best parameters for each model\n",
    "print(\"\\nBest Parameters:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    for param, value in result['best_params'].items():\n",
    "        print(f\"{param}: {value}\")\n",
    "\n",
    "# Print feature importance for Random Forest (as an example)\n",
    "rf_model = models['RandomForest']['model'].fit(X_train, y_train)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_transformed_df.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance (Random Forest):\")\n",
    "print(feature_importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
